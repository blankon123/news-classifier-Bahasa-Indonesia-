{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alur Preprocessing 2 (Text feature Extraction - Stemming)\n",
    "\n",
    "Alur dalam preprocessing ini yaitu dengan mengekstraksi kata-kata dengan beberapa metode. Alurnya adalah sebagai berikut\n",
    "\n",
    "1. Load Data\n",
    "2. Stemming and Stopwords Removal\n",
    "4. Vectorize\n",
    "4. Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import re #Regex\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the Labeled data from Description Section (1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just load it from the pickle dump\n",
    "DATA_JUDUL = pickle.load( open( \"v1.4\\DATA_JUDUL.p\", \"rb\" ) )\n",
    "DATA_SHORT = pickle.load( open( \"v1.4\\DATA_SHORT.p\", \"rb\" ) )\n",
    "DATA_LONG = pickle.load( open( \"v1.4\\DATA_LONG.p\", \"rb\" ) )\n",
    "\n",
    "DATA_TARGET = pickle.load( open( \"v1.4\\DATA_TARGET.p\", \"rb\" ) )\n",
    "\n",
    "DATA_JUDULStriped = pickle.load( open( \"v1.4\\DATA_JUDULStriped.p\", \"rb\" ) )\n",
    "DATA_SHORTStriped = pickle.load( open( \"v1.4\\DATA_SHORTStriped.p\", \"rb\" ) )\n",
    "DATA_LONGStriped = pickle.load( open( \"v1.4\\DATA_LONGStriped.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dua bumn kurang modal, benih subsidi langka'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_JUDULStriped[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Stemming and Stopwords Removal\n",
    "### This preproc focus on stemming (menjadikan kata dasar) and Stopwords (Seperti 'dan', 'ada', 'adalah') removal. This Section is for Preproc using Native Package (Sastrawi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import StemmerFactory class, github : https://github.com/masdevid/PySastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def rm_stem_native(teks):\n",
    "    # stemming process\n",
    "    teks   = stemmer.stem(teks) #Stemming\n",
    "    return teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya kata\n",
      "When the data Splitted           : 12\n",
      "After cleaning Html&Non-Alphanum : 7\n",
      "Sastrawi Result count            : 7\n",
      "\n",
      "<img src=\"http://cdn-media.viva.id/thumbs2/2015/12/18/354946_logo-bank-indonesia_663_382.jpg\" align=\"left\" hspace=\"7\" width=\"100\" />Permintaan kredit di enam sektor ekonomi melambat.\n",
      "\n",
      "permintaan kredit di enam sektor ekonomi melambat.\n",
      "\n",
      "minta kredit di enam sektor ekonomi lambat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teks_std = DATA_SHORT[98]\n",
    "teks = DATA_SHORTStriped[98]\n",
    "\n",
    "print 'Banyaknya kata'\n",
    "print ('When the data Splitted           : %s' % len(teks_std.split()))\n",
    "print ('After cleaning Html&Non-Alphanum : %s' % len(teks.split()))\n",
    "print ('Sastrawi Result count            : %s\\n' % len(rm_stem_native(teks).split()))\n",
    "\n",
    "print teks_std+'\\n'\n",
    "print teks + '\\n'\n",
    "print rm_stem_native(teks) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Didasarkan pada hasil diatas, proses Preprocessing selanjutnya akan menggunakan package native stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 29s\n",
      "Wall time: 1min 50s\n",
      "Wall time: 28min 11s\n"
     ]
    }
   ],
   "source": [
    "#Subsetting the Data, it's going to take more than 30 mins (in my case)\n",
    "%time DATA_JUDULStem = DATA_JUDULStriped.map(lambda x: rm_stem_native(x))\n",
    "%time DATA_SHORTStem = DATA_SHORTStriped.map(lambda x: rm_stem_native(x))\n",
    "%time DATA_LONGStem  = DATA_LONGStriped.map(lambda x: rm_stem_native(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Stopwords data source : https://www.illc.uva.nl/Research/Publications/Reports/MoL-2003-02.text.pdf\n",
    "stopword_html = open(\"id.stopwords.01.01.2016.txt\",'r').read()\n",
    "stopwords     = stopword_html.split(\"\\n\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def tableTop10(a,b,c):    \n",
    "    def topKWords(docs,k):\n",
    "        dummy  = docs.tolist()\n",
    "        countv = CountVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "        dummy  = countv.fit_transform(dummy)\n",
    "        freqs = [(word, dummy.getcol(idx).sum()) for word, idx in countv.vocabulary_.items()]\n",
    "        #sort from largest to smallest\n",
    "        return [name for name,freq in sorted(freqs, key = lambda x: -x[1])[0:k]]\n",
    "    \n",
    "    top_word = pd.DataFrame([topKWords(a,10),\n",
    "                             topKWords(b,10),\n",
    "                             topKWords(c,10)]).transpose()\n",
    "    return top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Kata paling tinggi Frekuensinya Pada teks Sebelum preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JudulS</th>\n",
       "      <th>ShortS</th>\n",
       "      <th>LongS</th>\n",
       "      <th>JudulP</th>\n",
       "      <th>ShortP</th>\n",
       "      <th>LongP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saham</td>\n",
       "      <td>pt</td>\n",
       "      <td>persen</td>\n",
       "      <td>saham</td>\n",
       "      <td>pt</td>\n",
       "      <td>persen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com</td>\n",
       "      <td>tbk</td>\n",
       "      <td>2016</td>\n",
       "      <td>com</td>\n",
       "      <td>tbk</td>\n",
       "      <td>usaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpnn</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>jpnn</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reklamasi</td>\n",
       "      <td>persen</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>harga</td>\n",
       "      <td>laku</td>\n",
       "      <td>indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>triliun</td>\n",
       "      <td>astra</td>\n",
       "      <td>pt</td>\n",
       "      <td>reklamasi</td>\n",
       "      <td>persen</td>\n",
       "      <td>laku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>harga</td>\n",
       "      <td>2016</td>\n",
       "      <td>harga</td>\n",
       "      <td>triliun</td>\n",
       "      <td>usaha</td>\n",
       "      <td>jakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>astra</td>\n",
       "      <td>harga</td>\n",
       "      <td>negara</td>\n",
       "      <td>turun</td>\n",
       "      <td>harga</td>\n",
       "      <td>harga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>saham</td>\n",
       "      <td>usaha</td>\n",
       "      <td>astra</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pemerintah</td>\n",
       "      <td>saham</td>\n",
       "      <td>perusahaan</td>\n",
       "      <td>jual</td>\n",
       "      <td>turun</td>\n",
       "      <td>kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>turun</td>\n",
       "      <td>triliun</td>\n",
       "      <td>triliun</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>2016</td>\n",
       "      <td>turun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       JudulS     ShortS       LongS     JudulP     ShortP      LongP\n",
       "0       saham         pt      persen      saham         pt     persen\n",
       "1         com        tbk        2016        com        tbk      usaha\n",
       "2        jpnn  indonesia   indonesia       jpnn  indonesia       2016\n",
       "3   reklamasi     persen     jakarta      harga       laku  indonesia\n",
       "4     triliun      astra          pt  reklamasi     persen       laku\n",
       "5       harga       2016       harga    triliun      usaha    jakarta\n",
       "6       astra      harga      negara      turun      harga      harga\n",
       "7   indonesia    jakarta       saham      usaha      astra         pt\n",
       "8  pemerintah      saham  perusahaan       jual      turun      kerja\n",
       "9       turun    triliun     triliun  indonesia       2016      turun"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_wordBerita1 = tableTop10(DATA_JUDULStriped,DATA_SHORTStriped,DATA_LONGStriped)\n",
    "top_wordBerita1.columns = ['JudulS','ShortS','LongS']\n",
    "top_wordBerita2 = tableTop10(DATA_JUDULStem,DATA_SHORTStem,DATA_LONGStem)\n",
    "top_wordBerita2.columns = ['JudulP','ShortP','LongP']\n",
    "\n",
    "top_wordBerita = [top_wordBerita1,top_wordBerita2]\n",
    "top_wordBerita = pd.concat(top_wordBerita,axis=1)\n",
    "print '10 Kata paling tinggi Frekuensinya Pada teks Sebelum preprocessing'\n",
    "top_wordBerita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Saving the data to file , it's 30mins processing time dude!\n",
    "pickle.dump( DATA_JUDULStem, open( \"v1.5\\DATA_JUDULStem.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_SHORTStem, open( \"v1.5\\DATA_SHORTStem.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_LONGStem, open( \"v1.5\\DATA_LONGStem.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_TARGET, open( \"v1.5\\DATA_TARGET.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
