{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alur Preprocessing 1 (Text feature Extraction - POS-Tagging)\n",
    "\n",
    "Alur dalam preprocessing ini yaitu dengan mengekstraksi kata-kata dengan beberapa metode. Alurnya adalah sebagai berikut\n",
    "\n",
    "1. Load Data\n",
    "2. POS-Tagging\n",
    "4. Vectorize\n",
    "5. Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from datetime import datetime as dt\n",
    "import cPickle as pickle\n",
    "import re #Regex\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just load it from the pickle dump\n",
    "DATA_JUDUL = pickle.load( open( \"v1.4\\DATA_JUDULStriped-v4a.p\", \"rb\" ) )\n",
    "DATA_SHORT = pickle.load( open( \"v1.4\\DATA_SHORTStriped-v4a.p\", \"rb\" ) )\n",
    "DATA_LONG = pickle.load( open( \"v1.4\\DATA_LONGStriped-v4a.p\", \"rb\" ) )\n",
    "DATA_TARGET = pickle.load( open( \"v1.4\\DATA_TARGET-v4a.p\", \"rb\" ) )\n",
    "\n",
    "#just load it from the pickle dump\n",
    "DATA_JUDUL_sk = pickle.load( open( \"v1.4\\DATA_JUDULStriped-v4c.p\", \"rb\" ) )\n",
    "DATA_SHORT_sk = pickle.load( open( \"v1.4\\DATA_SHORTStriped-v4c.p\", \"rb\" ) )\n",
    "DATA_LONG_sk = pickle.load( open( \"v1.4\\DATA_LONGStriped-v4c.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DATA_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%time postagger = pickle.load(open( \"POSTAGGER.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def onlyAZ(teks):\n",
    "    return re.sub(r'[^a-zA-Z]',' ', teks)\n",
    "    \n",
    "def onlyNVFromSentence(teks):\n",
    "    splitted = postagger.tag(onlyAZ(teks).split())\n",
    "    nouns = [word for word,pos in splitted \\\n",
    "        if (pos == 'NN' or pos == 'NNP' or \n",
    "            pos == 'NNS' or pos == 'VB')]\n",
    "    nounsSentence = string.join(nouns)\n",
    "    return nounsSentence\n",
    "\n",
    "def onlyNVFromParagraph(par):\n",
    "    splittedPar = par.split('.')\n",
    "    nounsPar = string.join([onlyNVFromSentence(i) for i in splittedPar])\n",
    "    return  nounsPar.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 77 ms\n",
      "Wall time: 209 ms\n",
      "Wall time: 2.4 s\n",
      "Wall time: 7 ms\n",
      "Wall time: 15 ms\n",
      "Wall time: 173 ms\n"
     ]
    }
   ],
   "source": [
    "#Time saver strategy\n",
    "%time DATA_JUDULPos = DATA_JUDUL.map(lambda x: onlyNVFromParagraph(x))\n",
    "%time DATA_SHORTPos = DATA_SHORT.map(lambda x: onlyNVFromParagraph(x))\n",
    "%time DATA_LONGPos  = DATA_LONG.map(lambda x: onlyNVFromParagraph(x))\n",
    "\n",
    "%time DATA_JUDUL_skPos = DATA_JUDUL_sk.map(lambda x: onlyNVFromParagraph(x))\n",
    "%time DATA_SHORT_skPos = DATA_SHORT_sk.map(lambda x: onlyNVFromParagraph(x))\n",
    "%time DATA_LONG_skPos  = DATA_LONG_sk.map(lambda x: onlyNVFromParagraph(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saat masih lajang memang kebutuhan tak terlalu mendesak.\n",
      "lajang kebutuhan mendesak\n"
     ]
    }
   ],
   "source": [
    "print DATA_SHORT[DATA_SHORT.index[0]]\n",
    "print DATA_SHORTPos[DATA_SHORTPos.index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorisasi\n",
    "\n",
    "##### Contoh Vektorisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara', 'antaranya', 'apa', 'apaan', 'apabila', 'apakah', 'apalagi', 'apatah', 'artinya', 'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal', 'awalnya', 'bagai', 'bagaikan', 'bagaimana', 'bagaimanakah', 'bagaimanapun', 'bagi', 'bagian', 'bahkan', 'bahwa', 'bahwasanya', 'baik', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah', 'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah', 'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah', 'benar', 'benarkah', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya', 'berapa', 'berapakah', 'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'beri', 'berikan', 'berikut', 'berikutnya', 'berjumlah', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan', 'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam', 'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap', 'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar', 'berupa', 'besar', 'betul', 'betulkah', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'bisakah', 'boleh', 'bolehkah', 'bolehlah', 'buat', 'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'cara', 'caranya', 'cukup', 'cukupkah', 'cukuplah', 'cuma', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi', 'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya', 'dialah', 'diantara', 'diantaranya', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat', 'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan', 'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan', 'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan', 'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah', 'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan', 'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan', 'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebut', 'disebutkan', 'disebutkannya', 'disini', 'disinilah', 'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk', 'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan', 'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'empat', 'enggak', 'enggaknya', 'entah', 'entahlah', 'guna', 'gunakan', 'hal', 'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'hendak', 'hendaklah', 'hendaknya', 'hingga', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut', 'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban', 'jawabnya', 'jelas', 'jelaskan', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kalian', 'kami', 'kamilah', 'kamu', 'kamulah', 'kan', 'kapan', 'kapankah', 'kapanpun', 'karena', 'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya', 'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan', 'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kenapa', 'kepada', 'kepadanya', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'lalu', 'lama', 'lamanya', 'lanjut', 'lanjutnya', 'lebih', 'lewat', 'lima', 'luar', 'macam', 'maka', 'makanya', 'makin', 'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya', 'masih', 'masihkah', 'masing', 'masing-masing', 'mau', 'maupun', 'melainkan', 'melakukan', 'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat', 'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan', 'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai', 'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti', 'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi', 'mendatangkan', 'menegaskan', 'mengakhiri', 'mengapa', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan', 'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan', 'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab', 'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjukkan', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan', 'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah', 'merupakan', 'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'nah', 'naik', 'namun', 'nanti', 'nantinya', 'nyaris', 'nyatanya', 'oleh', 'olehnya', 'pada', 'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting', 'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama', 'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'rasa', 'rasanya', 'rata', 'rupanya', 'saat', 'saatnya', 'saja', 'sajalah', 'saling', 'sama', 'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian', 'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum', 'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', 'sebut', 'sebutlah', 'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya', 'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah', 'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekarang', 'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela', 'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya', 'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya', 'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian', 'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya', 'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai', 'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat', 'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai', 'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', 'sudahkah', 'sudahlah', 'supaya', 'tadi', 'tadinya', 'tahu', 'tahun', 'tak', 'tambah', 'tambahnya', 'tampak', 'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya', 'telah', 'tempat', 'tengah', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak', 'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi', 'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan', 'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba', 'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'tinggi', 'toh', 'tunjuk', 'turut', 'tutur', 'tuturnya', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umum', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'waduh', 'wah', 'wahai', 'waktu', 'waktunya', 'walau', 'walaupun', 'wong', 'yaitu', 'yakin', 'yakni', 'yang']\n"
     ]
    }
   ],
   "source": [
    "#Stopwords data source : https://www.illc.uva.nl/Research/Publications/Reports/MoL-2003-02.text.pdf\n",
    "stopword_html = open(\"id.stopwords.01.01.2016.txt\",'r').read()\n",
    "stopwords     = stopword_html.split(\"\\n\")\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "docs = np.array([\n",
    "        'The sun is shining',\n",
    "        'The weather is sweet',\n",
    "        'The sun is shining and the weather is sweet'])\n",
    "#countv = TfidfVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "countv = TfidfVectorizer()\n",
    "dummy  = countv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>shining</th>\n",
       "      <th>sun</th>\n",
       "      <th>sweet</th>\n",
       "      <th>the</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  is  shining  sun  sweet  the  weather\n",
       "0    0   1        1    1      0    1        0\n",
       "1    0   1        0    0      1    1        1\n",
       "2    1   2        1    1      1    2        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "docs = np.array([\n",
    "        'The sun is shining',\n",
    "        'The weather is sweet',\n",
    "        'The sun is shining and the weather is sweet'])\n",
    "n_docs = len(docs)\n",
    "countv = CountVectorizer()\n",
    "dummy  = countv.fit_transform(docs)\n",
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(dummy.toarray(), columns=countv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2876820724517808"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_shining = 1.00\n",
    "df_shining = 2.00\n",
    "tf_shining*(np.log((n_docs+1)/(df_shining+1)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = np.array([\n",
    "        'The sun is shining',\n",
    "        'The weather is sweet',\n",
    "        'The sun is shining and the weather is sweet'])\n",
    "countv = TfidfVectorizer(norm=None)\n",
    "dummy  = countv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>shining</th>\n",
       "      <th>sun</th>\n",
       "      <th>sweet</th>\n",
       "      <th>the</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.693147</td>\n",
       "      <td>2</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>2</td>\n",
       "      <td>1.287682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  is   shining       sun     sweet  the   weather\n",
       "0  0.000000   1  1.287682  1.287682  0.000000    1  0.000000\n",
       "1  0.000000   1  0.000000  0.000000  1.287682    1  1.287682\n",
       "2  1.693147   2  1.287682  1.287682  1.287682    2  1.287682"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "dfDummy = pd.DataFrame(dummy.toarray(), columns=countv.get_feature_names())\n",
    "dfDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40474829,  0.47810172,  0.30782151,  0.30782151,  0.30782151,\n",
       "         0.47810172,  0.30782151]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_tfidfs_d3 = np.array([[ 1.69314718, 2.0, 1.28768207, 1.28768207, 1.28768207, 2.0, 1.28768207]])\n",
    "smooth_tfidfs_d3_norm = smooth_tfidfs_d3/np.sqrt(np.sum(smooth_tfidfs_d3**2))\n",
    "smooth_tfidfs_d3_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>shining</th>\n",
       "      <th>sun</th>\n",
       "      <th>sweet</th>\n",
       "      <th>the</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.558478</td>\n",
       "      <td>0.558478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558478</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.558478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404748</td>\n",
       "      <td>0.478102</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.478102</td>\n",
       "      <td>0.307822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and        is   shining       sun     sweet       the   weather\n",
       "0  0.000000  0.433708  0.558478  0.558478  0.000000  0.433708  0.000000\n",
       "1  0.000000  0.433708  0.000000  0.000000  0.558478  0.433708  0.558478\n",
       "2  0.404748  0.478102  0.307822  0.307822  0.307822  0.478102  0.307822"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The sun is shining',\n",
    "'The weather is sweet',\n",
    "'The sun is shining and the weather is sweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "docs = np.array([\n",
    "        'The sun is shining',\n",
    "        'The weather is sweet',\n",
    "        'The sun is shining and the weather is sweet'])\n",
    "n_docs = len(docs)\n",
    "countv = TfidfVectorizer()\n",
    "dummy  = countv.fit_transform(docs)\n",
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(dummy.toarray(), columns=countv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmStop(teks):\n",
    "    for i in stopwords:\n",
    "        teks = teks.replace(' '+i+' ',' ')\n",
    "    return len(teks.split())\n",
    "\n",
    "def rmStops(teks):\n",
    "    for i in stopwords:\n",
    "        teks = teks.replace(' '+i+' ',' ')\n",
    "    return teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "k1 = rmStop(DATA_SHORT[DATA_SHORT.index[i]])\n",
    "k2 = rmStop(DATA_SHORTPos[DATA_SHORTPos.index[i]])\n",
    "while (k1==k2):\n",
    "    i+=1\n",
    "    k1 = rmStop(DATA_SHORT[DATA_SHORT.index[i]])\n",
    "    k2 = rmStop(DATA_SHORTPos[DATA_SHORTPos.index[i]])\n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saat masih lajang memang kebutuhan tak terlalu mendesak.\n",
      "saat lajang kebutuhan mendesak.\n",
      "lajang kebutuhan mendesak\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print DATA_SHORT[DATA_SHORT.index[i]]\n",
    "print rmStops(DATA_SHORT[DATA_SHORT.index[i]])\n",
    "print rmStops(DATA_SHORTPos[DATA_SHORTPos.index[i]])\n",
    "DATA_SHORTPos.index[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektorisasi sudah termasuk menghilangkan karakter-karakter selain alphanumeric dan mengubah seluruh huruf menjadi huruf kecil. Kata 'ini', 'baik' , 'dengan' , dan 'sedang' hilang karena masuk dalam list stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking For Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def tableTop10(a,b,c):    \n",
    "    def topKWords(docs,k):\n",
    "        dummy  = docs.tolist()\n",
    "        countv = CountVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "        dummy  = countv.fit_transform(dummy)\n",
    "        freqs = [(word, dummy.getcol(idx).sum()) for word, idx in countv.vocabulary_.items()]\n",
    "        #sort from largest to smallest\n",
    "        return [name for name,freq in sorted(freqs, key = lambda x: -x[1])[0:k]]\n",
    "    \n",
    "    top_word = pd.DataFrame([topKWords(a,10),\n",
    "                             topKWords(b,10),\n",
    "                             topKWords(c,10)]).transpose()\n",
    "    return top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_wordBerita1 = tableTop10(DATA_JUDUL,DATA_SHORT,DATA_LONG)\n",
    "top_wordBerita1.columns = ['Judul','Short','Long']\n",
    "top_wordBerita2 = tableTop10(DATA_JUDULPos,DATA_SHORTPos,DATA_LONGPos)\n",
    "top_wordBerita2.columns = ['JudulPOSTag','ShortPOSTag','LongPOSTag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Kata paling tinggi Frekuensinya\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Short</th>\n",
       "      <th>Long</th>\n",
       "      <th>JudulPOSTag</th>\n",
       "      <th>ShortPOSTag</th>\n",
       "      <th>LongPOSTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air</td>\n",
       "      <td>pt</td>\n",
       "      <td>persen</td>\n",
       "      <td>rp</td>\n",
       "      <td>pt</td>\n",
       "      <td>rp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lion</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>2016</td>\n",
       "      <td>air</td>\n",
       "      <td>rp</td>\n",
       "      <td>saham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com</td>\n",
       "      <td>tbk</td>\n",
       "      <td>saham</td>\n",
       "      <td>lion</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jpnn</td>\n",
       "      <td>2016</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>com</td>\n",
       "      <td>tbk</td>\n",
       "      <td>jakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miliar</td>\n",
       "      <td>persen</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>jpnn</td>\n",
       "      <td>saham</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saham</td>\n",
       "      <td>saham</td>\n",
       "      <td>pt</td>\n",
       "      <td>miliar</td>\n",
       "      <td>laba</td>\n",
       "      <td>miliar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>triliun</td>\n",
       "      <td>laba</td>\n",
       "      <td>miliar</td>\n",
       "      <td>saham</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>perusahaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>laba</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>triliun</td>\n",
       "      <td>laba</td>\n",
       "      <td>miliar</td>\n",
       "      <td>laba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mnc</td>\n",
       "      <td>miliar</td>\n",
       "      <td>perusahaan</td>\n",
       "      <td>mnc</td>\n",
       "      <td>bank</td>\n",
       "      <td>perseroan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rp</td>\n",
       "      <td>bank</td>\n",
       "      <td>laba</td>\n",
       "      <td>dividen</td>\n",
       "      <td>harga</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Judul      Short        Long JudulPOSTag ShortPOSTag  LongPOSTag\n",
       "0      air         pt      persen          rp          pt          rp\n",
       "1     lion  indonesia        2016         air          rp       saham\n",
       "2      com        tbk       saham        lion   indonesia   indonesia\n",
       "3     jpnn       2016   indonesia         com         tbk     jakarta\n",
       "4   miliar     persen     jakarta        jpnn       saham          pt\n",
       "5    saham      saham          pt      miliar        laba      miliar\n",
       "6  triliun       laba      miliar       saham     jakarta  perusahaan\n",
       "7     laba    jakarta     triliun        laba      miliar        laba\n",
       "8      mnc     miliar  perusahaan         mnc        bank   perseroan\n",
       "9       rp       bank        laba     dividen       harga         air"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_wordBerita = [top_wordBerita1,top_wordBerita2]\n",
    "top_wordBerita = pd.concat(top_wordBerita,axis=1)\n",
    "print '10 Kata paling tinggi Frekuensinya'\n",
    "top_wordBerita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat bahwa perbedaan hasilnya cukup baik. Hal ini terkait dengan hilangnya beberapa kata yang tidak mengandung makna yang signifikan terhadap informasi yang dikandungnya. Contoh beberapa kata tersebut adalah 'triliun' dan 'persen'. Kata 'triliun' jika didalam kalimat kutipan maka tidak dihilangkan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'repatriasi mendatangkan dana rp berpengaruh menggairahkan pasar modal pasar uang perbankan menggerakkan sektor riil lapangan pekerjaan'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyNVFromParagraph('\"dengan repatriasi yang bisa mendatangkan dana rp 500 triliun, \\\n",
    "akan berpengaruh menggairahkan pasar modal, pasar uang dan perbankan. bahkan, bisa menggerakkan sektor riil (lapangan pekerjaan),\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump( DATA_JUDULPos, open( \"v1.6\\DATA_JUDULpostag-v5a.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_SHORTPos, open( \"v1.6\\DATA_SHORTpostag-v5a.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_LONGPos, open( \"v1.6\\DATA_LONGpostag-v5a.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_TARGET, open( \"v1.6\\DATA_TARGET-v5a.p\", \"wb\" ) )\n",
    "\n",
    "pickle.dump( DATA_JUDUL_skPos, open( \"v1.6\\DATA_JUDULpostag-v5c.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_SHORT_skPos, open( \"v1.6\\DATA_SHORTpostag-v5c.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_LONG_skPos, open( \"v1.6\\DATA_LONGpostag-v5c.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
