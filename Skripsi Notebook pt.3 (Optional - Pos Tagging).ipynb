{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alur Preprocessing 1 (Text feature Extraction - POS-Tagging)\n",
    "\n",
    "Alur dalam preprocessing ini yaitu dengan mengekstraksi kata-kata dengan beberapa metode. Alurnya adalah sebagai berikut\n",
    "\n",
    "1. Load Data\n",
    "2. POS-Tagging\n",
    "4. Vectorize\n",
    "5. Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from datetime import datetime as dt\n",
    "import cPickle as pickle\n",
    "import re #Regex\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidak bisa digabung dengan STEM dan Stopword Removal, karena POS-tagging akan maksimal hasilnya jika kalimat terstruktur, jika sudah di stem atau stopwordnya dihapus, maka strukturnya tidak akan bagus, sehingga dipakai yang belum di strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just load it from the pickle dump\n",
    "DATA_JUDUL = pickle.load( open( \"v1.4\\DATA_JUDULStriped-v2.p\", \"rb\" ) )\n",
    "DATA_SHORT = pickle.load( open( \"v1.4\\DATA_SHORTStriped-v2.p\", \"rb\" ) )\n",
    "DATA_LONG = pickle.load( open( \"v1.4\\DATA_LONGStriped-v2.p\", \"rb\" ) )\n",
    "DATA_TARGET = pickle.load( open( \"v1.4\\DATA_TARGET-v2.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.8 s\n"
     ]
    }
   ],
   "source": [
    "%time postagger = pickle.load(open( \"POSTAGGER.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def onlyAZ(teks):\n",
    "    return re.sub(r'[^a-zA-Z]',' ', teks)\n",
    "    \n",
    "def onlyNVFromSentence(teks):\n",
    "    splitted = postagger.tag(onlyAZ(teks).split())\n",
    "    nouns = [word for word,pos in splitted \\\n",
    "        if (pos == 'NN' or pos == 'NNP' or \n",
    "            pos == 'NNS' or pos == 'NNPS'or \n",
    "            pos == 'VB')]\n",
    "    nounsSentence = string.join(nouns)\n",
    "    return nounsSentence\n",
    "\n",
    "def onlyNVFromParagraph(par):\n",
    "    splittedPar = par.split('.')\n",
    "    nounsPar = string.join([onlyNVFromSentence(i) for i in splittedPar])\n",
    "    return  nounsPar.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 671 ms\n",
      "Wall time: 1.47 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "#Time saver strategy\n",
    "%time DATA_JUDULPos = DATA_JUDUL.map(lambda x: onlyNVFromParagraph(x))\n",
    "%time DATA_SHORTPos = DATA_SHORT.map(lambda x: onlyNVFromParagraph(x))\n",
    "%time DATA_LONGPos  = DATA_LONG.map(lambda x: onlyNVFromParagraph(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permintaan kredit di enam sektor ekonomi melambat.\n",
      "permintaan kredit sektor ekonomi melambat\n"
     ]
    }
   ],
   "source": [
    "print DATA_SHORT[98]\n",
    "print DATA_SHORTPos[98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorisasi\n",
    "\n",
    "##### Contoh Vektorisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Stopwords data source : https://www.illc.uva.nl/Research/Publications/Reports/MoL-2003-02.text.pdf\n",
    "stopword_html = open(\"id.stopwords.01.01.2016.txt\",'r').read()\n",
    "stopwords     = stopword_html.split(\"\\n\")\n",
    "\n",
    "ff = ['Ini adalah KALIMAT CONTOH!!',\n",
    "      'KaLiMat contoh ada 5800',\n",
    "      'kalimat yang dengan baik,kalimaT yang buruk,dan kalimat yang sedang 2016']\n",
    "dummy  = ff\n",
    "countv = TfidfVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "dummy  = countv.fit_transform(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016</th>\n",
       "      <th>5800</th>\n",
       "      <th>buruk</th>\n",
       "      <th>contoh</th>\n",
       "      <th>kalimat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789807</td>\n",
       "      <td>0.613356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.425441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2016      5800     buruk    contoh   kalimat\n",
       "0  0.000000  0.000000  0.000000  0.789807  0.613356\n",
       "1  0.000000  0.720333  0.000000  0.547832  0.425441\n",
       "2  0.441105  0.000000  0.441105  0.000000  0.781571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(dummy.toarray(), columns=countv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektorisasi sudah termasuk menghilangkan karakter-karakter selain alphanumeric dan mengubah seluruh huruf menjadi huruf kecil. Kata 'ini', 'baik' , 'dengan' , dan 'sedang' hilang karena masuk dalam list stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking For Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def tableTop10(a,b,c):    \n",
    "    def topKWords(docs,k):\n",
    "        dummy  = docs.tolist()\n",
    "        countv = CountVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "        dummy  = countv.fit_transform(dummy)\n",
    "        freqs = [(word, dummy.getcol(idx).sum()) for word, idx in countv.vocabulary_.items()]\n",
    "        #sort from largest to smallest\n",
    "        return [name for name,freq in sorted(freqs, key = lambda x: -x[1])[0:k]]\n",
    "    \n",
    "    top_word = pd.DataFrame([topKWords(a,10),\n",
    "                             topKWords(b,10),\n",
    "                             topKWords(c,10)]).transpose()\n",
    "    return top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_wordBerita1 = tableTop10(DATA_JUDUL,DATA_SHORT,DATA_LONG)\n",
    "top_wordBerita1.columns = ['Judul','Short','Long']\n",
    "top_wordBerita2 = tableTop10(DATA_JUDULPos,DATA_SHORTPos,DATA_LONGPos)\n",
    "top_wordBerita2.columns = ['JudulPOSTag','ShortPOSTag','LongPOSTag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Kata paling tinggi Frekuensinya Pada teks Sebelum preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Short</th>\n",
       "      <th>Long</th>\n",
       "      <th>JudulPOSTag</th>\n",
       "      <th>ShortPOSTag</th>\n",
       "      <th>LongPOSTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>rp</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jpnn</td>\n",
       "      <td>pt</td>\n",
       "      <td>persen</td>\n",
       "      <td>com</td>\n",
       "      <td>pt</td>\n",
       "      <td>rp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>2016</td>\n",
       "      <td>jpnn</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>jakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harga</td>\n",
       "      <td>pemerintah</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>rp</td>\n",
       "      <td>harga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jokowi</td>\n",
       "      <td>harga</td>\n",
       "      <td>harga</td>\n",
       "      <td>harga</td>\n",
       "      <td>pemerintah</td>\n",
       "      <td>pemerintah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rumah</td>\n",
       "      <td>2016</td>\n",
       "      <td>pemerintah</td>\n",
       "      <td>jokowi</td>\n",
       "      <td>harga</td>\n",
       "      <td>negara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>saham</td>\n",
       "      <td>persen</td>\n",
       "      <td>negara</td>\n",
       "      <td>rumah</td>\n",
       "      <td>bank</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ekonomi</td>\n",
       "      <td>bank</td>\n",
       "      <td>pt</td>\n",
       "      <td>saham</td>\n",
       "      <td>saham</td>\n",
       "      <td>rumah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pemerintah</td>\n",
       "      <td>saham</td>\n",
       "      <td>rumah</td>\n",
       "      <td>ekonomi</td>\n",
       "      <td>negara</td>\n",
       "      <td>perusahaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>triliun</td>\n",
       "      <td>negara</td>\n",
       "      <td>perusahaan</td>\n",
       "      <td>pemerintah</td>\n",
       "      <td>rumah</td>\n",
       "      <td>pasar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Judul       Short        Long JudulPOSTag ShortPOSTag  LongPOSTag\n",
       "0         com   indonesia   indonesia          rp   indonesia   indonesia\n",
       "1        jpnn          pt      persen         com          pt          rp\n",
       "2   indonesia     jakarta        2016        jpnn     jakarta     jakarta\n",
       "3       harga  pemerintah     jakarta   indonesia          rp       harga\n",
       "4      jokowi       harga       harga       harga  pemerintah  pemerintah\n",
       "5       rumah        2016  pemerintah      jokowi       harga      negara\n",
       "6       saham      persen      negara       rumah        bank          pt\n",
       "7     ekonomi        bank          pt       saham       saham       rumah\n",
       "8  pemerintah       saham       rumah     ekonomi      negara  perusahaan\n",
       "9     triliun      negara  perusahaan  pemerintah       rumah       pasar"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_wordBerita = [top_wordBerita1,top_wordBerita2]\n",
    "top_wordBerita = pd.concat(top_wordBerita,axis=1)\n",
    "print '10 Kata paling tinggi Frekuensinya Pada teks Sebelum preprocessing'\n",
    "top_wordBerita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat bahwa perbedaan hasilnya cukup baik. Hal ini terkait dengan hilangnya beberapa kata yang tidak mengandung makna yang signifikan terhadap informasi yang dikandungnya. Contoh beberapa kata tersebut adalah 'triliun' dan 'persen'. Kata 'triliun' jika didalam kalimat kutipan maka tidak dihilangkan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'repatriasi mendatangkan dana rp berpengaruh menggairahkan pasar modal pasar uang perbankan menggerakkan sektor riil lapangan pekerjaan'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyNVFromParagraph('\"dengan repatriasi yang bisa mendatangkan dana rp 500 triliun, \\\n",
    "akan berpengaruh menggairahkan pasar modal, pasar uang dan perbankan. bahkan, bisa menggerakkan sektor riil (lapangan pekerjaan),\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump( DATA_JUDULPos, open( \"v1.6\\DATA_JUDULpostag-v2.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_SHORTPos, open( \"v1.6\\DATA_SHORTpostag-v2.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_LONGPos, open( \"v1.6\\DATA_LONGpostag-v2.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_TARGET, open( \"v1.6\\DATA_TARGET-v2.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
