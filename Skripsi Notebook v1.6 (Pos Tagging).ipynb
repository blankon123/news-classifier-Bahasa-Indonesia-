{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alur Preprocessing 1 (Text feature Extraction - POS-Tagging)\n",
    "\n",
    "Alur dalam preprocessing ini yaitu dengan mengekstraksi kata-kata dengan beberapa metode. Alurnya adalah sebagai berikut\n",
    "\n",
    "1. Load Data\n",
    "2. POS-Tagging\n",
    "4. Vectorize\n",
    "5. Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from datetime import datetime as dt\n",
    "import cPickle as pickle\n",
    "import re #Regex\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidak bisa digabung dengan STEM dan Stopword Removal, karena POS-tagging akan maksimal hasilnya jika kalimat terstruktur, jika sudah di stem atau stopwordnya dihapus, maka strukturnya tidak akan bagus, sehingga dipakai yang belum di strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just load it from the pickle dump\n",
    "DATA_JUDUL = pickle.load( open( \"v1.4\\DATA_JUDULStriped.p\", \"rb\" ) )\n",
    "DATA_SHORT = pickle.load( open( \"v1.4\\DATA_SHORTStriped.p\", \"rb\" ) )\n",
    "DATA_LONG = pickle.load( open( \"v1.4\\DATA_LONGStriped.p\", \"rb\" ) )\n",
    "DATA_TARGET = pickle.load( open( \"v1.4\\DATA_TARGET.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%time postagger = pickle.load(open( \"POSTAGGER.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def onlyNounsFromSentence(teks):\n",
    "    splitted = postagger.tag(teks.split())\n",
    "    nouns = [word for word,pos in splitted \\\n",
    "        if (pos == 'NN' or pos == 'NNP' or \n",
    "            pos == 'NNS' or pos == 'NNPS'or \n",
    "            pos == 'VB')]\n",
    "    nounsSentence = string.join(nouns)\n",
    "    return nounsSentence\n",
    "\n",
    "def onlyNounsFromParagraph(par):\n",
    "    splittedPar = par.split('.')\n",
    "    nounsPar = string.join([onlyNounsFromSentence(i) for i in splittedPar])\n",
    "    return  nounsPar.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32 ms\n",
      "Wall time: 24 ms\n",
      "Wall time: 459 ms\n"
     ]
    }
   ],
   "source": [
    "#Subsetting the Data\n",
    "\n",
    "#Time saver strategy\n",
    "%time DATA_JUDULPos = DATA_JUDUL.map(lambda x: onlyNounsFromParagraph(x))\n",
    "%time DATA_SHORTPos = DATA_SHORT.map(lambda x: onlyNounsFromParagraph(x))\n",
    "%time DATA_LONGPos  = DATA_LONG.map(lambda x: onlyNounsFromParagraph(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'permintaan kredit sektor ekonomi melambat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SHORTPos[98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorisasi\n",
    "\n",
    "##### Contoh Vektorisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Stopwords data source : https://www.illc.uva.nl/Research/Publications/Reports/MoL-2003-02.text.pdf\n",
    "stopword_html = open(\"id.stopwords.01.01.2016.txt\",'r').read()\n",
    "stopwords     = stopword_html.split(\"\\n\")\n",
    "\n",
    "ff = ['Ini adalah KALIMAT CONTOH!!',\n",
    "      'KaLiMat contoh ada 5800',\n",
    "      'kalimat yang dengan baik,kalimaT yang buruk,dan kalimat yang sedang 2016']\n",
    "dummy  = ff\n",
    "countv = TfidfVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "dummy  = countv.fit_transform(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016</th>\n",
       "      <th>5800</th>\n",
       "      <th>buruk</th>\n",
       "      <th>contoh</th>\n",
       "      <th>kalimat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789807</td>\n",
       "      <td>0.613356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.425441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2016      5800     buruk    contoh   kalimat\n",
       "0  0.000000  0.000000  0.000000  0.789807  0.613356\n",
       "1  0.000000  0.720333  0.000000  0.547832  0.425441\n",
       "2  0.441105  0.000000  0.441105  0.000000  0.781571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(dummy.toarray(), columns=countv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektorisasi sudah termasuk menghilangkan karakter-karakter selain alphanumeric dan mengubah seluruh huruf menjadi huruf kecil. Kata 'ini', 'baik' , 'dengan' , dan 'sedang' hilang karena masuk dalam list stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking For Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def tableTop10(a,b,c):    \n",
    "    def topKWords(docs,k):\n",
    "        dummy  = docs.tolist()\n",
    "        countv = CountVectorizer(stop_words=stopwords,decode_error='ignore')\n",
    "        dummy  = countv.fit_transform(dummy)\n",
    "        freqs = [(word, dummy.getcol(idx).sum()) for word, idx in countv.vocabulary_.items()]\n",
    "        #sort from largest to smallest\n",
    "        return [name for name,freq in sorted(freqs, key = lambda x: -x[1])[0:k]]\n",
    "    \n",
    "    top_word = pd.DataFrame([topKWords(a,10),\n",
    "                             topKWords(b,10),\n",
    "                             topKWords(c,10)]).transpose()\n",
    "    return top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_wordBerita1 = tableTop10(DATA_JUDUL,DATA_SHORT,DATA_LONG)\n",
    "top_wordBerita1.columns = ['JudulS','ShortS','LongS']\n",
    "top_wordBerita2 = tableTop10(DATA_JUDULPos,DATA_SHORTPos,DATA_LONGPos)\n",
    "top_wordBerita2.columns = ['JudulP','ShortP','LongP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Kata paling tinggi Frekuensinya Pada teks Sebelum preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JudulS</th>\n",
       "      <th>ShortS</th>\n",
       "      <th>LongS</th>\n",
       "      <th>JudulP</th>\n",
       "      <th>ShortP</th>\n",
       "      <th>LongP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saham</td>\n",
       "      <td>pt</td>\n",
       "      <td>persen</td>\n",
       "      <td>saham</td>\n",
       "      <td>pt</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com</td>\n",
       "      <td>tbk</td>\n",
       "      <td>2016</td>\n",
       "      <td>com</td>\n",
       "      <td>tbk</td>\n",
       "      <td>indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jpnn</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>jpnn</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>jakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reklamasi</td>\n",
       "      <td>persen</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>reklamasi</td>\n",
       "      <td>astra</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>triliun</td>\n",
       "      <td>astra</td>\n",
       "      <td>pt</td>\n",
       "      <td>harga</td>\n",
       "      <td>2016</td>\n",
       "      <td>harga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>harga</td>\n",
       "      <td>2016</td>\n",
       "      <td>harga</td>\n",
       "      <td>astra</td>\n",
       "      <td>harga</td>\n",
       "      <td>negara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>astra</td>\n",
       "      <td>harga</td>\n",
       "      <td>negara</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>saham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>saham</td>\n",
       "      <td>pemerintah</td>\n",
       "      <td>saham</td>\n",
       "      <td>perusahaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pemerintah</td>\n",
       "      <td>saham</td>\n",
       "      <td>perusahaan</td>\n",
       "      <td>turun</td>\n",
       "      <td>pemerintah</td>\n",
       "      <td>pemerintah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>turun</td>\n",
       "      <td>triliun</td>\n",
       "      <td>triliun</td>\n",
       "      <td>mnc</td>\n",
       "      <td>pajak</td>\n",
       "      <td>minyak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       JudulS     ShortS       LongS      JudulP      ShortP       LongP\n",
       "0       saham         pt      persen       saham          pt        2016\n",
       "1         com        tbk        2016         com         tbk   indonesia\n",
       "2        jpnn  indonesia   indonesia        jpnn   indonesia     jakarta\n",
       "3   reklamasi     persen     jakarta   reklamasi       astra          pt\n",
       "4     triliun      astra          pt       harga        2016       harga\n",
       "5       harga       2016       harga       astra       harga      negara\n",
       "6       astra      harga      negara   indonesia     jakarta       saham\n",
       "7   indonesia    jakarta       saham  pemerintah       saham  perusahaan\n",
       "8  pemerintah      saham  perusahaan       turun  pemerintah  pemerintah\n",
       "9       turun    triliun     triliun         mnc       pajak      minyak"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_wordBerita = [top_wordBerita1,top_wordBerita2]\n",
    "top_wordBerita = pd.concat(top_wordBerita,axis=1)\n",
    "print '10 Kata paling tinggi Frekuensinya Pada teks Sebelum preprocessing'\n",
    "top_wordBerita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat bahwa perbedaan hasilnya cukup baik. Hal ini terkait dengan hilangnya beberapa kata yang tidak mengandung makna yang signifikan terhadap informasi yang dikandungnya. Contoh beberapa kata tersebut adalah 'triliun' dan 'persen'. Kata 'triliun' jika didalam kalimat kutipan maka tidak dihilangkan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dengan repatriasi mendatangkan dana rp triliun  berpengaruh menggairahkan pasar modal  pasar uang perbankan bahkan  menggerakkan sektor riil  lapangan pekerjaan'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyNounsFromParagraph('\"dengan repatriasi yang bisa mendatangkan dana rp 500 triliun, \\\n",
    "akan berpengaruh menggairahkan pasar modal, pasar uang dan perbankan. bahkan, bisa menggerakkan sektor riil (lapangan pekerjaan),\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump( DATA_JUDULPos, open( \"v1.6\\DATA_JUDULpostag.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_SHORTPos, open( \"v1.6\\DATA_SHORTpostag.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_LONGPos, open( \"v1.6\\DATA_LONGpostag.p\", \"wb\" ) )\n",
    "pickle.dump( DATA_TARGET, open( \"v1.6\\DATA_TARGET.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
